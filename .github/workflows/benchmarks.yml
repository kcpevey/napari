# This CI configuration for relative benchmarks is based on the research done
# for scikit-image's implementation available here:
# https://github.com/scikit-image/scikit-image/blob/9bdd010a8/.github/workflows/benchmarks.yml#L1
# Blog post with the rationale: https://labs.quansight.org/blog/2021/08/github-actions-benchmarks/

name: Benchmarks

on:
  pull_request:
    types: [labeled]
  schedule:
    - cron: "6 6 * * 0" # every sunday
  workflow_dispatch:
    inputs:
      base_ref:
        description: "Baseline commit or git reference"
        required: true
      contender_ref:
        description: "Contender commit or git reference"
        required: true

# This is the main configuration section that needs to be fine tuned to napari's needs
# All the *_THREADS options is just to make the benchmarks more robust by not using parallelism
env:
  OPENBLAS_NUM_THREADS: "1"
  MKL_NUM_THREADS: "1"
  OMP_NUM_THREADS: "1"
  ASV_OPTIONS: "--split --show-stderr --factor 1.5 -a timeout=300"
  # --split -> split final reports in tables
  # --show-stderr -> print tracebacks if errors occur
  # --factor 1.5 -> report anomaly if tested timings are beyond 1.5x base timings
  # -a timeout=300 -> override timeout attribute (defaults to 60s) to allow slow tests to run

jobs:
  benchmark:
    if: ${{ github.event.label.name == 'run-benchmarks' && github.event_name == 'pull_request' || github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}
    name: ${{ matrix.benchmark-name }}
    runs-on: ${{ matrix.runs-on }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - benchmark-name: Qt
            asv-command: continuous
            selection-regex: "^benchmark_qt_.*"
            runs-on: macos-latest
          - benchmark-name: non-Qt
            asv-command: continuous
            selection-regex: "^benchmark_(?!qt_).*"
            runs-on: ubuntu-latest

    steps:
      # We need the full repo to avoid this issue
      # https://github.com/actions/checkout/issues/23
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v3
        name: Install Python
        with:
          python-version: "3.9"

      - uses: tlambert03/setup-qt-libs@v1

      - name: Setup asv
        run: python -m pip install asv virtualenv

      - uses: octokit/request-action@v2.x
        id: latest_release
        with:
          route: GET /repos/{owner}/{repo}/releases/latest
          owner: napari
          repo: napari
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Run ${{ matrix.benchmark-name }} benchmarks
        env:
          # asv will checkout commits, which might contain LFS artifacts; ignore those errors since
          # they are probably just documentation PNGs not needed here anyway
          GIT_LFS_SKIP_SMUDGE: 1
        run: |
          set -euxo pipefail

          # ID this runner
          asv machine --yes

          if [[ $GITHUB_EVENT_NAME == pull_request ]]; then
            BASE_REF=${BASE_REF}
            CONTENDER_REF=${GITHUB_SHA}
            echo "Baseline:  ${BASE_REF} (${{ github.event.pull_request.base.label }})"
            echo "Contender: ${CONTENDER_REF} (${{ github.event.pull_request.head.label }})"
          elif [[ $GITHUB_EVENT_NAME == schedule ]]; then
            BASE_REF="${{ fromJSON(steps.latest_release.outputs.data).target_commitish }}"
            CONTENDER_REF="${GITHUB_SHA}"
            echo "Baseline:  ${BASE_REF} (${{ fromJSON(steps.latest_release.outputs.data).tag_name }})"
            echo "Contender: ${CONTENDER_REF} (current main)"
          elif [[ $GITHUB_EVENT_NAME == workflow_dispatch ]]; then
            BASE_REF="${{ github.event.inputs.base_ref }}""
            CONTENDER_REF="${{ github.event.inputs.contender_ref }}"
            echo "Baseline:  ${BASE_REF} (workflow input)"
            echo "Contender: ${CONTENDER_REF} (workflow input)"
          else
            echo "Unsupported event!"
            exit 1
          fi

          # Run benchmarks for current commit against base
          asv continuous $ASV_OPTIONS -b '${{ matrix.selection-regex }}' ${BASE_REF} ${CONTENDER_REF} \
          | sed -E "/Traceback | failed$|PERFORMANCE DECREASED/ s/^/::error:: /" \
          | tee benchmarks.log

          # Report and export results for subsequent steps
          if grep "Traceback \|failed\|PERFORMANCE DECREASED" benchmarks.log > /dev/null ; then
              exit 1
          fi

      - name: Add instructions to artifact
        if: always()
        run: cp benchmarks.log .asv/results/

      - uses: actions/upload-artifact@v3
        if: always()
        with:
          name: asv-benchmark-results-${{ github.sha }}-${{ matrix.benchmark-name }}
          path: .asv/results
